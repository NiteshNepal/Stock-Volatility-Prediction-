{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmadashfaq/pinokio/api/oobabooga.pinokio.git/text-generation-webui/installer_files/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed:   59.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7763\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 0.003863\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CallbackEnv' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 274\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubmission saved with RMSPE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmspe_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 274\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 263\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    261\u001b[0m X \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    262\u001b[0m y \u001b[38;5;241m=\u001b[39m Y_train\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 263\u001b[0m rmspe_score \u001b[38;5;241m=\u001b[39m \u001b[43mtemporal_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m final_model, _, test_preds \u001b[38;5;241m=\u001b[39m train_and_predict(X, X, y, y, X_test)\n\u001b[1;32m    266\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_id\u001b[39m\u001b[38;5;124m'\u001b[39m: sample_submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m: test_preds\n\u001b[1;32m    269\u001b[0m })\n",
      "Cell \u001b[0;32mIn[1], line 250\u001b[0m, in \u001b[0;36mtemporal_validation\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    248\u001b[0m X_train_fold, X_val \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_idx], X\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[1;32m    249\u001b[0m y_train_fold, y_val \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_idx], y\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[0;32m--> 250\u001b[0m model, val_preds, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m fold_score \u001b[38;5;241m=\u001b[39m rmspe(y_val, val_preds)\n\u001b[1;32m    252\u001b[0m all_val_scores\u001b[38;5;241m.\u001b[39mappend(fold_score)\n",
      "Cell \u001b[0;32mIn[1], line 192\u001b[0m, in \u001b[0;36mtrain_and_predict\u001b[0;34m(X_train, X_val, y_train, y_val, X_test)\u001b[0m\n\u001b[1;32m    190\u001b[0m callback, train_rmspe_history, val_rmspe_history \u001b[38;5;241m=\u001b[39m training_callback()\n\u001b[1;32m    191\u001b[0m lgb_model \u001b[38;5;241m=\u001b[39m LGBMRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlgb_params)\n\u001b[0;32m--> 192\u001b[0m \u001b[43mlgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# CatBoost\u001b[39;00m\n\u001b[1;32m    200\u001b[0m cat_model \u001b[38;5;241m=\u001b[39m CatBoostRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcat_params)\n",
      "File \u001b[0;32m~/pinokio/api/oobabooga.pinokio.git/text-generation-webui/installer_files/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:1189\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1174\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/pinokio/api/oobabooga.pinokio.git/text-generation-webui/installer_files/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/pinokio/api/oobabooga.pinokio.git/text-generation-webui/installer_files/conda/lib/python3.10/site-packages/lightgbm/engine.py:317\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_after_iter:\n\u001b[0;32m--> 317\u001b[0m         \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCallbackEnv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbooster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m                \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m                \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbegin_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m                \u001b[49m\u001b[43mend_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_iteration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m                \u001b[49m\u001b[43mevaluation_result_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_result_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m callback\u001b[38;5;241m.\u001b[39mEarlyStopException \u001b[38;5;28;01mas\u001b[39;00m earlyStopException:\n\u001b[1;32m    328\u001b[0m     booster\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;241m=\u001b[39m earlyStopException\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 149\u001b[0m, in \u001b[0;36mtraining_callback.<locals>.callback\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcallback\u001b[39m(env):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Record every 100 iterations\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m         train_pred \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Training data\u001b[39;00m\n\u001b[1;32m    150\u001b[0m         val_pred \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(env\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m1\u001b[39m])    \u001b[38;5;66;03m# Validation data\u001b[39;00m\n\u001b[1;32m    151\u001b[0m         train_rmspe \u001b[38;5;241m=\u001b[39m rmspe(Y_train\u001b[38;5;241m.\u001b[39miloc[env\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex], train_pred)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CallbackEnv' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "from scipy.stats import kurtosis\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = r'/Users/ahmadashfaq/Stock-Volatility-Prediction-/optiver-realized-volatility-prediction'\n",
    "df_train_raw = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "df_test_raw = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "sample_submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "\n",
    "# Feature Engineering Functions (Enhanced from both models)\n",
    "def calc_wap1(df):\n",
    "    return (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "\n",
    "def calc_wap2(df):\n",
    "    return (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "\n",
    "def log_return(series):\n",
    "    return np.log(series).diff().fillna(0)\n",
    "\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "def book_preprocess(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # WAP and Log Returns (from both models)\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['log_ret1'] = df.groupby('time_id')['wap1'].transform(log_return)\n",
    "    df['log_ret2'] = df.groupby('time_id')['wap2'].transform(log_return)\n",
    "    \n",
    "    # Volatility Features\n",
    "    df['volatility'] = df.groupby('time_id')['log_ret1'].transform(realized_volatility)\n",
    "    df['volatility_5min'] = df[df['seconds_in_bucket'] <= 300].groupby('time_id')['log_ret1'].transform(realized_volatility)\n",
    "    df['wap_balance'] = df['wap1'] - df['wap2']  # From previous model\n",
    "    \n",
    "    # Order Book Features\n",
    "    df['spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['imbalance'] = (df['bid_size1'] - df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    df['total_volume'] = df['ask_size1'] + df['ask_size2'] + df['bid_size1'] + df['bid_size2']  # From previous model\n",
    "    \n",
    "    # Time-based Features\n",
    "    df['time_norm'] = df['seconds_in_bucket'] / 600\n",
    "    \n",
    "    # Aggregations (enhanced)\n",
    "    agg_dict = {\n",
    "        'wap1': ['mean', 'std', 'skew'],\n",
    "        'wap2': ['mean', 'std'],\n",
    "        'log_ret1': ['std', 'skew', realized_volatility],\n",
    "        'log_ret2': ['std'],\n",
    "        'spread': ['mean', 'std', 'max'],\n",
    "        'imbalance': ['mean', 'std'],\n",
    "        'volatility': ['mean'],\n",
    "        'volatility_5min': ['mean'],\n",
    "        'bid_size1': ['sum'],\n",
    "        'ask_size1': ['sum'],\n",
    "        'wap_balance': ['mean', 'std'],\n",
    "        'total_volume': ['mean', 'std'],\n",
    "        'time_norm': ['mean', 'std']\n",
    "    }\n",
    "    df_agg = df.groupby('time_id').agg(agg_dict).reset_index()\n",
    "    df_agg.columns = ['time_id'] + ['_'.join(col) if isinstance(col, tuple) else col for col in df_agg.columns[1:]]\n",
    "    \n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_agg['row_id'] = str(stock_id) + '-' + df_agg['time_id'].astype(str)\n",
    "    df_agg.drop('time_id', axis=1, inplace=True)\n",
    "    return df_agg\n",
    "\n",
    "def trade_preprocess(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_ret'] = df.groupby('time_id')['price'].transform(log_return)\n",
    "    df['trade_intensity'] = df['size'] / df['order_count']  # From previous enhancement\n",
    "    \n",
    "    agg_dict = {\n",
    "        'log_ret': ['std', 'mean'],\n",
    "        'size': ['sum', 'mean'],\n",
    "        'order_count': ['sum'],\n",
    "        'trade_intensity': ['mean']\n",
    "    }\n",
    "    df_agg = df.groupby('time_id').agg(agg_dict).reset_index()\n",
    "    df_agg.columns = ['time_id'] + ['_'.join(col) if isinstance(col, tuple) else col for col in df_agg.columns[1:]]\n",
    "    \n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_agg['row_id'] = str(stock_id) + '-' + df_agg['time_id'].astype(str)\n",
    "    df_agg.drop('time_id', axis=1, inplace=True)\n",
    "    return df_agg\n",
    "\n",
    "def preprocessor(stock_id_list, train_mode=True):\n",
    "    df = Parallel(n_jobs=-1, verbose=1)(\n",
    "        delayed(lambda x: pd.merge(book_preprocess(f'{DATA_DIR}/{\"book_train\" if train_mode else \"book_test\"}.parquet/stock_id={x}'),\n",
    "                                 trade_preprocess(f'{DATA_DIR}/{\"trade_train\" if train_mode else \"trade_test\"}.parquet/stock_id={x}'),\n",
    "                                 on='row_id', how='left'))(stock_id) \n",
    "        for stock_id in stock_id_list\n",
    "    )\n",
    "    return pd.concat(df, ignore_index=True)\n",
    "\n",
    "# Data Processing\n",
    "train_stock_id_list = df_train_raw['stock_id'].unique()\n",
    "df_train = preprocessor(train_stock_id_list, train_mode=True)\n",
    "df_train = pd.merge(df_train, \n",
    "                   df_train_raw.assign(row_id=lambda x: x['stock_id'].astype(str) + '-' + x['time_id'].astype(str))[['row_id', 'target']],\n",
    "                   on='row_id', how='right')\n",
    "df_train['stock_id'] = df_train['row_id'].str.split('-').str[0].astype('category')\n",
    "df_train['time_id'] = df_train['row_id'].str.split('-').str[1].astype(int)\n",
    "\n",
    "test_stock_id_list = df_test_raw['stock_id'].unique()\n",
    "df_test = preprocessor(test_stock_id_list, train_mode=False)\n",
    "df_test = pd.merge(df_test, \n",
    "                  df_test_raw.assign(row_id=lambda x: x['stock_id'].astype(str) + '-' + x['time_id'].astype(str))[['row_id']],\n",
    "                  on='row_id', how='right')\n",
    "df_test['stock_id'] = df_test['row_id'].str.split('-').str[0].astype('category')\n",
    "df_test['time_id'] = df_test['row_id'].str.split('-').str[1].astype(int)\n",
    "\n",
    "# Data Preparation (No explicit imputation - let LightGBM handle NaNs)\n",
    "X_train = df_train.drop(columns=['target', 'row_id'])\n",
    "Y_train = df_train['target']\n",
    "X_test = df_test.drop(columns=['row_id'])\n",
    "\n",
    "t_encoder = ce.TargetEncoder(smoothing=10)\n",
    "X_train['stock_id'] = t_encoder.fit_transform(X_train['stock_id'], Y_train)\n",
    "X_test['stock_id'] = t_encoder.transform(X_test['stock_id'])\n",
    "\n",
    "# RMSPE Metric\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Training Process Callback for LightGBM\n",
    "def training_callback():\n",
    "    train_rmspe_history = []\n",
    "    val_rmspe_history = []\n",
    "    \n",
    "    def callback(env):\n",
    "        if env.iteration % 100 == 0:  # Record every 100 iterations\n",
    "            train_pred = env.model.predict(env.data[0])  # Training data\n",
    "            val_pred = env.model.predict(env.data[1])    # Validation data\n",
    "            train_rmspe = rmspe(Y_train.iloc[env.data[0].index], train_pred)\n",
    "            val_rmspe = rmspe(Y_train.iloc[env.data[1].index], val_pred)\n",
    "            train_rmspe_history.append(train_rmspe)\n",
    "            val_rmspe_history.append(val_rmspe)\n",
    "            print(f\"Iteration {env.iteration}: Train RMSPE = {train_rmspe:.4f}, Val RMSPE = {val_rmspe:.4f}\")\n",
    "    \n",
    "    return callback, train_rmspe_history, val_rmspe_history\n",
    "\n",
    "# Model Definitions (Incorporating previous tuning)\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'learning_rate': 0.005,  # From previous model\n",
    "    'num_leaves': 80,\n",
    "    'max_depth': 6,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.01,\n",
    "    'colsample_bytree': 0.1,\n",
    "    'subsample': 0.01,\n",
    "    'n_estimators': 1500,\n",
    "    'random_state': 2025\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 1500,\n",
    "    'learning_rate': 0.005,\n",
    "    'depth': 8,\n",
    "    'l2_leaf_reg': 3.0,\n",
    "    'bagging_temperature': 0.2,\n",
    "    'random_seed': 2025,\n",
    "    'verbose': 100\n",
    "}\n",
    "\n",
    "# Enhanced Model with Training Monitoring\n",
    "def train_and_predict(X_train, X_val, y_train, y_val, X_test):\n",
    "    # Split for validation\n",
    "    train_idx = X_train.index\n",
    "    val_idx = X_val.index\n",
    "    \n",
    "    # LightGBM with callback\n",
    "    callback, train_rmspe_history, val_rmspe_history = training_callback()\n",
    "    lgb_model = LGBMRegressor(**lgb_params)\n",
    "    lgb_model.fit(\n",
    "        X_train.drop(columns=['time_id']), y_train,\n",
    "        eval_set=[(X_train.drop(columns=['time_id']), y_train), (X_val.drop(columns=['time_id']), y_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[callback]\n",
    "    )\n",
    "    \n",
    "    # CatBoost\n",
    "    cat_model = CatBoostRegressor(**cat_params)\n",
    "    cat_model.fit(X_train.drop(columns=['time_id']), y_train, verbose=100)\n",
    "    \n",
    "    # MLP\n",
    "    mlp_model = MLPRegressor(hidden_layer_sizes=(256, 128, 64), early_stopping=True, random_state=42, max_iter=500)\n",
    "    mlp_model.fit(X_train.drop(columns=['time_id']), y_train)\n",
    "    \n",
    "    # Ensemble (Combining Voting from previous model with Stacking)\n",
    "    voting_model = VotingRegressor([\n",
    "        ('lgb', lgb_model),\n",
    "        ('cat', cat_model),\n",
    "        ('mlp', mlp_model)\n",
    "    ], weights=[0.4, 0.35, 0.25])  # Adjusted weights from previous model\n",
    "    \n",
    "    final_model = StackingRegressor(\n",
    "        estimators=[\n",
    "            ('voting', voting_model)\n",
    "        ],\n",
    "        final_estimator=Ridge(alpha=1.0)\n",
    "    )\n",
    "    \n",
    "    final_model.fit(X_train.drop(columns=['time_id']), y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    val_preds = final_model.predict(X_val.drop(columns=['time_id']))\n",
    "    test_preds = final_model.predict(X_test.drop(columns=['time_id']))\n",
    "    test_preds = np.clip(test_preds, Y_train.min(), Y_train.max())\n",
    "    \n",
    "    # Plot training process\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(0, len(train_rmspe_history) * 100, 100), train_rmspe_history, label='Train RMSPE')\n",
    "    plt.plot(range(0, len(val_rmspe_history) * 100, 100), val_rmspe_history, label='Validation RMSPE')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('RMSPE')\n",
    "    plt.title('Training Process: RMSPE over Iterations (LightGBM)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return final_model, val_preds, test_preds\n",
    "\n",
    "# Temporal Validation\n",
    "def temporal_validation(X, y):\n",
    "    cv = GroupKFold(n_splits=5)\n",
    "    group_ids = X['time_id']\n",
    "    all_val_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y, groups=group_ids)):\n",
    "        X_train_fold, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        model, val_preds, _ = train_and_predict(X_train_fold, X_val, y_train_fold, y_val, X_test)\n",
    "        fold_score = rmspe(y_val, val_preds)\n",
    "        all_val_scores.append(fold_score)\n",
    "        print(f'Fold {fold+1} RMSPE: {fold_score:.4f}')\n",
    "    \n",
    "    overall_rmspe = np.mean(all_val_scores)\n",
    "    print(f'Overall RMSPE: {overall_rmspe:.4f}')\n",
    "    return overall_rmspe\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "    X = X_train.copy()\n",
    "    y = Y_train.copy()\n",
    "    rmspe_score = temporal_validation(X, y)\n",
    "    \n",
    "    final_model, _, test_preds = train_and_predict(X, X, y, y, X_test)\n",
    "    submission = pd.DataFrame({\n",
    "        'row_id': sample_submission['row_id'],\n",
    "        'target': test_preds\n",
    "    })\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(f\"Submission saved with RMSPE: {rmspe_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
